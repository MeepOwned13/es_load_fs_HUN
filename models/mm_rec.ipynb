{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2127fb1c16e351a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import trainer_lib as tl\n",
    "import torch_model_definitions as tmd\n",
    "\n",
    "torch.manual_seed(310231551)\n",
    "random.seed(3009231410)\n",
    "np.random.seed(2909231846)\n",
    "np_random_state = np.random.RandomState(131002)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72e279db9c1942c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df: pd.DataFrame = tl.load_country_wide_dataset('../data/country_data.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3521fa8ffa005679"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a476da50926e0c38"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, features=11, hidden_size=15, num_layers=2, dropout=0.0, hid_noise=0.0,\n",
    "                 bidirectional=True, **kwargs):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.h_n_dim = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "        rec_drop = dropout if num_layers > 1 else 0.0\n",
    "        self.lstm = nn.LSTM(input_size=features, hidden_size=self.hidden_size, num_layers=num_layers, batch_first=True,\n",
    "                            bidirectional=bidirectional, dropout=rec_drop)\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            tmd.GaussianNoise(hid_noise),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.hidden_size * self.h_n_dim * self.num_layers, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h_0 = torch.zeros(self.h_n_dim * self.num_layers, batch_size, self.hidden_size).requires_grad_().to(\n",
    "            tl.TRAINER_LIB_DEVICE)\n",
    "        c_0 = torch.zeros(self.h_n_dim * self.num_layers, batch_size, self.hidden_size).requires_grad_().to(\n",
    "            tl.TRAINER_LIB_DEVICE)\n",
    "\n",
    "        output, (h_n, c_n) = self.lstm(x, (h_0, c_0))\n",
    "        h_n = torch.permute(h_n, (1, 0, 2))\n",
    "        return self.fc(h_n) \n",
    "\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, features=11, hidden_size=15, num_layers=2, dropout=0.0, hid_noise=0.0,\n",
    "                 bidirectional=True, **kwargs):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.h_n_dim = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "        rec_drop = dropout if num_layers > 1 else 0.0\n",
    "        self.gru = nn.GRU(input_size=features, hidden_size=self.hidden_size, num_layers=num_layers, batch_first=True,\n",
    "                          bidirectional=bidirectional, dropout=rec_drop)\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            tmd.GaussianNoise(hid_noise),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.hidden_size * self.h_n_dim * self.num_layers, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        hidden = torch.zeros(self.h_n_dim * self.num_layers, batch_size, self.hidden_size).requires_grad_().to(\n",
    "            tl.TRAINER_LIB_DEVICE)\n",
    "\n",
    "        output, hidden = self.gru(x, hidden)\n",
    "        hidden = torch.permute(hidden, (1, 0, 2))\n",
    "        return self.fc(hidden)\n",
    "    \n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, channels=(32, 64), kernel_sizes=(12, 6), noise_sigma=0.0, dropout=0.0, **kwargs):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.seq_len = 24\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.ZeroPad2d((kernel_sizes[0] // 2, 0, 0, 0)),\n",
    "            nn.Conv1d(1, channels[0], kernel_sizes[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, padding=1),\n",
    "            nn.ZeroPad2d((kernel_sizes[1] // 2, 0, 0, 0)),\n",
    "            nn.Conv1d(channels[0], channels[1], kernel_sizes[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, padding=0),\n",
    "        )\n",
    "        out = self.conv(torch.randn(1, 1, self.seq_len)).shape[-1]\n",
    "        self.fc = nn.Sequential(\n",
    "            tmd.GaussianNoise(noise_sigma),\n",
    "            nn.Flatten(1, -1),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(channels[1] * out, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 1, self.seq_len)\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, num_channels=(24,) * 2, kernel_size=3, dropout=0.5, hid_noise=0.0, **kwargs):\n",
    "        super(TCN, self).__init__()\n",
    "        self.seq_len = 24\n",
    "        self.pred_len = 1\n",
    "        self.num_channels = num_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dropout = dropout\n",
    "        self.tcn = tmd.TemporalConvNet(1, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.hid_noise = tmd.GaussianNoise(hid_noise)\n",
    "        self.fc = nn.Linear(num_channels[-1], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 1, self.seq_len)\n",
    "        x = self.tcn(x)\n",
    "        x = self.hid_noise(x)\n",
    "        return self.fc(x[:, :, -1])\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ea6d43079ba4bf1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Individual testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88cdfed965d8ac15"
  },
  {
   "cell_type": "markdown",
   "source": [
    "    ### precipitation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f5db73352d73df1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df['prec'].to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.0005],\n",
    "    'model': [ConvNet],\n",
    "    'kernel_sizes': [(12, 6), (10, 10), (6, 12)],\n",
    "    'channels': [(8, 16), (16, 32)],\n",
    "    'noise_sigma': [0.05],\n",
    "    'dropout': [0.5],\n",
    "    'batch_size': [2048],\n",
    "})\n",
    "\n",
    "wrapper: tl.RECOneModelTSWrapper = tl.RECOneModelTSWrapper(ConvNet(), 24, 3)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=2)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a71fbf4e95d3f7e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df['prec'].to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [TCN],\n",
    "    'kernel_size': [3, 5],\n",
    "    'num_channels': [(16, 32), (32, 32)],\n",
    "    'noise_sigma': [0.05],\n",
    "    'dropout': [0.5],\n",
    "    'batch_size': [2048],\n",
    "})\n",
    "\n",
    "wrapper: tl.RECOneModelTSWrapper = tl.RECOneModelTSWrapper(TCN(), 24, 3)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=2)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfab923ddb8bfe24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df['prec'].to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [LSTMModel, GRUModel],\n",
    "    'features': [1],\n",
    "    'hidden_size': [15, 20],\n",
    "    'num_layers': [2],\n",
    "    'bidirectional': [True],\n",
    "    'hid_noise': [0.05],\n",
    "    'dropout': [0.5],\n",
    "    'batch_size': [2048],\n",
    "})\n",
    "\n",
    "wrapper: tl.RECOneModelTSWrapper = tl.RECOneModelTSWrapper(GRUModel(), 24, 3)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=2)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6044574bcc4670c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### global radiation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a925561471d352ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df['grad'].to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.0005],\n",
    "    'model': [ConvNet],\n",
    "    'kernel_sizes': [(12, 6), (10, 10), (6, 12)],\n",
    "    'channels': [(8, 16), (16, 32)],\n",
    "    'noise_sigma': [0.05],\n",
    "    'dropout': [0.5],\n",
    "    'batch_size': [2048],\n",
    "})\n",
    "\n",
    "wrapper: tl.RECOneModelTSWrapper = tl.RECOneModelTSWrapper(ConvNet(), 24, 3)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=2)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de8bb48e37d0fc32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df['grad'].to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [TCN],\n",
    "    'kernel_size': [3, 5],\n",
    "    'num_channels': [(16, 32), (32, 32)],\n",
    "    'noise_sigma': [0.05],\n",
    "    'dropout': [0.5],\n",
    "    'batch_size': [2048],\n",
    "})\n",
    "\n",
    "wrapper: tl.RECOneModelTSWrapper = tl.RECOneModelTSWrapper(TCN(), 24, 3)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=2)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77202b165f34fcb8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df['grad'].to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [LSTMModel, GRUModel],\n",
    "    'features': [1],\n",
    "    'hidden_size': [10, 15, 20],\n",
    "    'num_layers': [2],\n",
    "    'bidirectional': [True],\n",
    "    'hid_noise': [0.05],\n",
    "    'dropout': [0.5],\n",
    "    'batch_size': [2048],\n",
    "})\n",
    "\n",
    "wrapper: tl.RECOneModelTSWrapper = tl.RECOneModelTSWrapper(GRUModel(), 24, 3)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=2)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4da047fd78a33b87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### el_load non-recursive"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a74195079189303c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = df['el_load'].to_numpy(dtype=np.float32)\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [LSTMModel, GRUModel],\n",
    "    'hidden_size': [15, 25, 35],\n",
    "    'num_layers': [2, 3],\n",
    "    'bidirectional': [True],\n",
    "    'batch_size': [2048],\n",
    "    'dropout': [0.5],\n",
    "    'hid_noise': [0.05],\n",
    "})\n",
    "\n",
    "wrapper: tl.MIMOTSWrapper = tl.MIMOTSWrapper(LSTMModel(), seq_len=24, pred_len=1)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=3)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ced78b5203c0289"
  },
  {
   "cell_type": "markdown",
   "source": [
    "No major differences here, in the first run GRU with 25 hidden size and 2 layers were the best"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c645aca6444d053c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = df['el_load'].to_numpy(dtype=np.float32)\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [LSTMModel, GRUModel],\n",
    "    'hidden_size': [10, 15],\n",
    "    'num_layers': [2],\n",
    "    'bidirectional': [True],\n",
    "    'batch_size': [2048],\n",
    "    'dropout': [0.5],\n",
    "    'hid_noise': [0.05],\n",
    "})\n",
    "\n",
    "wrapper: tl.MIMOTSWrapper = tl.MIMOTSWrapper(LSTMModel(), seq_len=24, pred_len=1)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=3)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be7e8870906e3ee5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "let's try a single layer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ab7212d25b41cda"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = df['el_load'].to_numpy(dtype=np.float32)\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [GRUModel],\n",
    "    'hidden_size': [25, 30, 35],\n",
    "    'num_layers': [1],\n",
    "    'bidirectional': [True],\n",
    "    'batch_size': [2048],\n",
    "    'dropout': [0.5],\n",
    "    'hid_noise': [0.05],\n",
    "    'es_p': [20],\n",
    "})\n",
    "\n",
    "wrapper: tl.MIMOTSWrapper = tl.MIMOTSWrapper(GRUModel(), seq_len=24, pred_len=1)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=3)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4c93943c91919"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = df['el_load'].to_numpy(dtype=np.float32)\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [GRUModel],\n",
    "    'hidden_size': [40, 45],\n",
    "    'num_layers': [1],\n",
    "    'bidirectional': [True],\n",
    "    'batch_size': [2048],\n",
    "    'dropout': [0.5],\n",
    "    'hid_noise': [0.05],\n",
    "    'es_p': [20],\n",
    "})\n",
    "\n",
    "wrapper: tl.MIMOTSWrapper = tl.MIMOTSWrapper(GRUModel(), seq_len=24, pred_len=1)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=3)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdd19ed313306c0f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### putting it all together"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d9233c21ff70f8f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MultiModelRec(nn.Module):\n",
    "    def __init__(self, features=11, pred_len=3, hidden_size=15, num_layers=2, dropout=0.0,\n",
    "                 hid_noise=0.0, bidirectional=True,  **kwargs):\n",
    "        super(MultiModelRec, self).__init__()\n",
    "        self.out_features = 3\n",
    "        self.pred_len = pred_len\n",
    "        \n",
    "        self.gru = GRUModel(features, hidden_size, num_layers, dropout, hid_noise, bidirectional)\n",
    "        self.tcn = TCN((32,) * 2, kernel_size=5, dropout=dropout, hid_noise=hid_noise)\n",
    "        self.conv = ConvNet((16, 32), (6, 12), 0.5, 0.05)\n",
    "\n",
    "\n",
    "    def forward(self, x, y, teacher_forcing=0.0):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        if y.shape[2] != self.gru.gru.input_size:\n",
    "            pre_calc = torch.concat((\n",
    "                torch.zeros(batch_size, self.pred_len, self.out_features).to(tl.TRAINER_LIB_DEVICE),\n",
    "                y), dim=2)\n",
    "            teacher_forcing = 0.0\n",
    "        else:\n",
    "            pre_calc = y\n",
    "\n",
    "        output = torch.zeros(batch_size, self.pred_len).to(tl.TRAINER_LIB_DEVICE)\n",
    "\n",
    "        for i in range(self.pred_len):\n",
    "            out = torch.concat((\n",
    "                self.gru(x),\n",
    "                self.tcn(x[:, :, 1]),\n",
    "                self.conv(x[:, :, 2])\n",
    "            ), dim=1)\n",
    "\n",
    "            output[:, i] = out[:, 0]\n",
    "            \n",
    "            x = torch.cat((x[:, 1:], pre_calc[:, i].unsqueeze(1)), dim=1)\n",
    "            for j in range(self.out_features):  # roll teacher forcing for each feature\n",
    "                if torch.rand(1) > teacher_forcing:\n",
    "                    x[:, -1, j] = out[:, j]\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [MultiModelRec],\n",
    "    'hidden_size': [25, 30, 35],\n",
    "    'num_layers': [2],\n",
    "    'bidirectional': [True],\n",
    "    'batch_size': [1024],\n",
    "    'dropout': [0.5],\n",
    "    'hid_noise': [0.05],\n",
    "    'es_p': [20],\n",
    "})\n",
    "\n",
    "wrap: tl.RECMultiModelTSWrapper = tl.RECMultiModelTSWrapper(MultiModelRec(), 24, 3, 3, teacher_forcing_decay=0.01)\n",
    "b_p, b_s = wrap.grid_search(X, y, grid, verbose=4)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21eda4dd279fe33c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [MultiModelRec],\n",
    "    'hidden_size': [55, 50, 45],\n",
    "    'num_layers': [1],\n",
    "    'bidirectional': [True],\n",
    "    'batch_size': [1024],\n",
    "    'dropout': [0.5],\n",
    "    'hid_noise': [0.05],\n",
    "    'es_p': [25],\n",
    "})\n",
    "\n",
    "wrap: tl.RECMultiModelTSWrapper = tl.RECMultiModelTSWrapper(MultiModelRec(), 24, 3, 3, teacher_forcing_decay=0.01)\n",
    "b_p, b_s = wrap.grid_search(X, y, grid, verbose=4)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90b967ef803762f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
