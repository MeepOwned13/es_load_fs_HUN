{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2127fb1c16e351a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-18T10:56:17.542929800Z",
     "start_time": "2024-01-18T10:56:09.485885200Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import trainer_lib as tl\n",
    "import torch_model_definitions as tmd\n",
    "\n",
    "torch.manual_seed(310231551)\n",
    "random.seed(3009231410)\n",
    "np.random.seed(2909231846)\n",
    "np_random_state = np.random.RandomState(131002)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72e279db9c1942c1"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                      el_load      prec  grad  holiday  weekend  hour  \\\nTime                                                                    \n2015-01-01 00:00:00  4270.718  0.000000   0.0      1.0      0.0     0   \n2015-01-01 01:00:00  4068.940  0.000000   0.0      1.0      0.0     1   \n2015-01-01 02:00:00  3754.788  0.000000   0.0      1.0      0.0     2   \n2015-01-01 03:00:00  3510.361  0.000000   0.0      1.0      0.0     3   \n2015-01-01 04:00:00  3426.489  0.000000   0.0      1.0      0.0     4   \n...                       ...       ...   ...      ...      ...   ...   \n2023-08-31 19:00:00  5480.864  0.020588   0.0      0.0      0.0    19   \n2023-08-31 20:00:00  5139.191  0.037255   0.0      0.0      0.0    20   \n2023-08-31 21:00:00  4849.395  0.000980   0.0      0.0      0.0    21   \n2023-08-31 22:00:00  4652.292  0.000000   0.0      0.0      0.0    22   \n2023-08-31 23:00:00  4364.219  0.000000   0.0      0.0      0.0    23   \n\n                     weekday  dayofyear  month  year  el_load_lag24  \nTime                                                                 \n2015-01-01 00:00:00        3          1      1  2015          0.000  \n2015-01-01 01:00:00        3          1      1  2015          0.000  \n2015-01-01 02:00:00        3          1      1  2015          0.000  \n2015-01-01 03:00:00        3          1      1  2015          0.000  \n2015-01-01 04:00:00        3          1      1  2015          0.000  \n...                      ...        ...    ...   ...            ...  \n2023-08-31 19:00:00        3        243      8  2023       5403.837  \n2023-08-31 20:00:00        3        243      8  2023       5110.462  \n2023-08-31 21:00:00        3        243      8  2023       4840.584  \n2023-08-31 22:00:00        3        243      8  2023       4643.627  \n2023-08-31 23:00:00        3        243      8  2023       4387.782  \n\n[75960 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>el_load</th>\n      <th>prec</th>\n      <th>grad</th>\n      <th>holiday</th>\n      <th>weekend</th>\n      <th>hour</th>\n      <th>weekday</th>\n      <th>dayofyear</th>\n      <th>month</th>\n      <th>year</th>\n      <th>el_load_lag24</th>\n    </tr>\n    <tr>\n      <th>Time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2015-01-01 00:00:00</th>\n      <td>4270.718</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2015</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2015-01-01 01:00:00</th>\n      <td>4068.940</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2015</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2015-01-01 02:00:00</th>\n      <td>3754.788</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2015</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2015-01-01 03:00:00</th>\n      <td>3510.361</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2015</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2015-01-01 04:00:00</th>\n      <td>3426.489</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2015</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2023-08-31 19:00:00</th>\n      <td>5480.864</td>\n      <td>0.020588</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>19</td>\n      <td>3</td>\n      <td>243</td>\n      <td>8</td>\n      <td>2023</td>\n      <td>5403.837</td>\n    </tr>\n    <tr>\n      <th>2023-08-31 20:00:00</th>\n      <td>5139.191</td>\n      <td>0.037255</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20</td>\n      <td>3</td>\n      <td>243</td>\n      <td>8</td>\n      <td>2023</td>\n      <td>5110.462</td>\n    </tr>\n    <tr>\n      <th>2023-08-31 21:00:00</th>\n      <td>4849.395</td>\n      <td>0.000980</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>21</td>\n      <td>3</td>\n      <td>243</td>\n      <td>8</td>\n      <td>2023</td>\n      <td>4840.584</td>\n    </tr>\n    <tr>\n      <th>2023-08-31 22:00:00</th>\n      <td>4652.292</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>22</td>\n      <td>3</td>\n      <td>243</td>\n      <td>8</td>\n      <td>2023</td>\n      <td>4643.627</td>\n    </tr>\n    <tr>\n      <th>2023-08-31 23:00:00</th>\n      <td>4364.219</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>23</td>\n      <td>3</td>\n      <td>243</td>\n      <td>8</td>\n      <td>2023</td>\n      <td>4387.782</td>\n    </tr>\n  </tbody>\n</table>\n<p>75960 rows Ã— 11 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df: pd.DataFrame = tl.load_country_wide_dataset('../data/country_data.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T10:56:17.755211Z",
     "start_time": "2024-01-18T10:56:17.542929800Z"
    }
   },
   "id": "3521fa8ffa005679"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a476da50926e0c38"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, features=11, hidden_size=15, num_layers=2, dropout=0.0, hid_noise=0.0,\n",
    "                 bidirectional=True, **kwargs):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.h_n_dim = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "        rec_drop = dropout if num_layers > 1 else 0.0\n",
    "        self.lstm = nn.LSTM(input_size=features, hidden_size=self.hidden_size, num_layers=num_layers, batch_first=True,\n",
    "                            bidirectional=bidirectional, dropout=rec_drop)\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            tmd.GaussianNoise(hid_noise),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.hidden_size * self.h_n_dim * self.num_layers, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h_0 = torch.zeros(self.h_n_dim * self.num_layers, batch_size, self.hidden_size).to(\n",
    "            tl.TRAINER_LIB_DEVICE)\n",
    "        c_0 = torch.zeros(self.h_n_dim * self.num_layers, batch_size, self.hidden_size).to(\n",
    "            tl.TRAINER_LIB_DEVICE)\n",
    "\n",
    "        output, (h_n, c_n) = self.lstm(x, (h_0, c_0))\n",
    "        h_n = torch.permute(h_n, (1, 0, 2))\n",
    "        return self.fc(h_n) \n",
    "\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, features=11, hidden_size=15, num_layers=2, dropout=0.0, hid_noise=0.0,\n",
    "                 bidirectional=True, **kwargs):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.h_n_dim = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "        rec_drop = dropout if num_layers > 1 else 0.0\n",
    "        self.gru = nn.GRU(input_size=features, hidden_size=self.hidden_size, num_layers=num_layers, batch_first=True,\n",
    "                          bidirectional=bidirectional, dropout=rec_drop)\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            tmd.GaussianNoise(hid_noise),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.hidden_size * self.h_n_dim * self.num_layers, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        hidden = torch.zeros(self.h_n_dim * self.num_layers, batch_size, self.hidden_size).to(\n",
    "            tl.TRAINER_LIB_DEVICE)\n",
    "\n",
    "        output, hidden = self.gru(x, hidden)\n",
    "        hidden = torch.permute(hidden, (1, 0, 2))\n",
    "        return self.fc(hidden)\n",
    "    \n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, channels=(32, 64), kernel_sizes=(12, 6), noise_sigma=0.0, dropout=0.0, **kwargs):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.seq_len = 24\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.ZeroPad2d((kernel_sizes[0] // 2, 0, 0, 0)),\n",
    "            nn.Conv1d(1, channels[0], kernel_sizes[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, padding=1),\n",
    "            nn.ZeroPad2d((kernel_sizes[1] // 2, 0, 0, 0)),\n",
    "            nn.Conv1d(channels[0], channels[1], kernel_sizes[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, padding=0),\n",
    "        )\n",
    "        out = self.conv(torch.randn(1, 1, self.seq_len)).shape[-1]\n",
    "        self.fc = nn.Sequential(\n",
    "            tmd.GaussianNoise(noise_sigma),\n",
    "            nn.Flatten(1, -1),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(channels[1] * out, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 1, self.seq_len)\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, num_channels=(24,) * 2, kernel_size=3, dropout=0.5, hid_noise=0.0, **kwargs):\n",
    "        super(TCN, self).__init__()\n",
    "        self.seq_len = 24\n",
    "        self.pred_len = 1\n",
    "        self.num_channels = num_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dropout = dropout\n",
    "        self.tcn = tmd.TemporalConvNet(1, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.hid_noise = tmd.GaussianNoise(hid_noise)\n",
    "        self.fc = nn.Linear(num_channels[-1], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 1, self.seq_len)\n",
    "        x = self.tcn(x)\n",
    "        x = self.hid_noise(x)\n",
    "        return self.fc(x[:, :, -1])\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T10:56:26.008715100Z",
     "start_time": "2024-01-18T10:56:26.006706400Z"
    }
   },
   "id": "1ea6d43079ba4bf1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Individual testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88cdfed965d8ac15"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### precipitation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f5db73352d73df1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df['prec'].to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.0005],\n",
    "    'model': [ConvNet],\n",
    "    'kernel_sizes': [(12, 6), (10, 10), (6, 12)],\n",
    "    'channels': [(8, 16), (16, 32)],\n",
    "    'noise_sigma': [0.05],\n",
    "    'dropout': [0.5],\n",
    "    'batch_size': [2048],\n",
    "})\n",
    "\n",
    "wrapper: tl.RECOneModelTSWrapper = tl.RECOneModelTSWrapper(ConvNet(), 24, 3)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=2)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a71fbf4e95d3f7e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df['prec'].to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [TCN],\n",
    "    'kernel_size': [3, 5],\n",
    "    'num_channels': [(16, 32), (32, 32)],\n",
    "    'noise_sigma': [0.05],\n",
    "    'dropout': [0.5],\n",
    "    'batch_size': [2048],\n",
    "})\n",
    "\n",
    "wrapper: tl.RECOneModelTSWrapper = tl.RECOneModelTSWrapper(TCN(), 24, 3)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=2)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfab923ddb8bfe24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df['prec'].to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [LSTMModel, GRUModel],\n",
    "    'features': [1],\n",
    "    'hidden_size': [15, 20],\n",
    "    'num_layers': [2],\n",
    "    'bidirectional': [True],\n",
    "    'hid_noise': [0.05],\n",
    "    'dropout': [0.5],\n",
    "    'batch_size': [2048],\n",
    "})\n",
    "\n",
    "wrapper: tl.RECOneModelTSWrapper = tl.RECOneModelTSWrapper(GRUModel(), 24, 3)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=2)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6044574bcc4670c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try external features, will only predict 1 hour ahead here, the MMRec will give us the rest."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95e5f5eba6937475"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Grid search 001] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'model': <class '__main__.LSTMModel'>, 'features': 10, 'hidden_size': 15, 'num_layers': 2, 'bidirectional': True, 'hid_noise': 0.05, 'dropout': 0.5, 'batch_size': 2048}\n",
      "[Fold 1] BEGIN - END - RMSE loss: 0.091 - Time: 0.8 min.\n",
      "[Fold 2] BEGIN - END - RMSE loss: 0.095 - Time: 0.4 min.\n",
      "[Fold 3] BEGIN - END - RMSE loss: 0.074 - Time: 0.3 min.\n",
      "[Fold 4] BEGIN - END - RMSE loss: 0.073 - Time: 1.2 min.\n",
      "[Fold 5] BEGIN - END - RMSE loss: 0.061 - Time: 0.8 min.\n",
      "[Fold 6] BEGIN - END - RMSE loss: 0.083 - Time: 0.5 min.\n",
      "[Grid search 001] END - Score: 0.07941002 * Without 1st split: 0.07718142086759339\n",
      "[Grid search 002] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'model': <class '__main__.GRUModel'>, 'features': 10, 'hidden_size': 15, 'num_layers': 2, 'bidirectional': True, 'hid_noise': 0.05, 'dropout': 0.5, 'batch_size': 2048}\n",
      "[Fold 1] BEGIN - END - RMSE loss: 0.080 - Time: 1.0 min.\n",
      "[Fold 2] BEGIN - END - RMSE loss: 0.098 - Time: 0.3 min.\n",
      "[Fold 3] BEGIN - END - RMSE loss: 0.070 - Time: 0.5 min.\n",
      "[Fold 4] BEGIN - END - RMSE loss: 0.072 - Time: 0.8 min.\n",
      "[Fold 5] BEGIN - END - RMSE loss: 0.060 - Time: 1.1 min.\n",
      "[Fold 6] BEGIN - END - RMSE loss: 0.082 - Time: 0.6 min.\n",
      "[Grid search 002] END - Score: 0.07716624 * Without 1st split: 0.07658710988998611\n",
      "[Grid search 003] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'model': <class '__main__.LSTMModel'>, 'features': 10, 'hidden_size': 20, 'num_layers': 2, 'bidirectional': True, 'hid_noise': 0.05, 'dropout': 0.5, 'batch_size': 2048}\n",
      "[Fold 1] BEGIN - END - RMSE loss: 0.090 - Time: 0.5 min.\n",
      "[Fold 2] BEGIN - END - RMSE loss: 0.093 - Time: 0.3 min.\n",
      "[Fold 3] BEGIN - END - RMSE loss: 0.074 - Time: 0.4 min.\n",
      "[Fold 4] BEGIN - END - RMSE loss: 0.072 - Time: 1.0 min.\n",
      "[Fold 5] BEGIN - END - RMSE loss: 0.060 - Time: 1.1 min.\n",
      "[Fold 6] BEGIN - END - RMSE loss: 0.082 - Time: 0.6 min.\n",
      "[Grid search 003] END - Score: 0.07854154 Without 1st split: 0.07626541715212029\n",
      "[Grid search 004] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'model': <class '__main__.GRUModel'>, 'features': 10, 'hidden_size': 20, 'num_layers': 2, 'bidirectional': True, 'hid_noise': 0.05, 'dropout': 0.5, 'batch_size': 2048}\n",
      "[Fold 1] BEGIN - END - RMSE loss: 0.077 - Time: 0.9 min.\n",
      "[Fold 2] BEGIN - END - RMSE loss: 0.094 - Time: 0.3 min.\n",
      "[Fold 3] BEGIN - END - RMSE loss: 0.074 - Time: 0.3 min.\n",
      "[Fold 4] BEGIN - END - RMSE loss: 0.073 - Time: 0.7 min.\n",
      "[Fold 5] BEGIN - END - RMSE loss: 0.060 - Time: 1.3 min.\n",
      "[Fold 6] BEGIN - END - RMSE loss: 0.082 - Time: 0.5 min.\n",
      "[Grid search 004] END - Score: 0.07661414 * Without 1st split: 0.07651980325873915\n",
      "\n",
      "Best params: {'epochs': 1000, 'lr': 0.001, 'model': <class '__main__.GRUModel'>, 'features': 10, 'hidden_size': 20, 'num_layers': 2, 'bidirectional': True, 'hid_noise': 0.05, 'dropout': 0.5, 'batch_size': 2048}\n",
      "Best score: 0.07661413731302498\n"
     ]
    }
   ],
   "source": [
    "X = df.to_numpy(dtype=np.float32)[:, 1:] # remove el_load\n",
    "y = df['prec'].to_numpy(dtype=np.float32)\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [LSTMModel, GRUModel],\n",
    "    'features': [10],\n",
    "    'hidden_size': [15, 20],\n",
    "    'num_layers': [2],\n",
    "    'bidirectional': [True],\n",
    "    'hid_noise': [0.05],\n",
    "    'dropout': [0.5],\n",
    "    'batch_size': [2048],\n",
    "})\n",
    "\n",
    "wrapper: tl.MIMOTSWrapper = tl.MIMOTSWrapper(GRUModel(), seq_len=24, pred_len=1)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=3)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T11:17:15.143163Z",
     "start_time": "2024-01-18T11:01:04.229404900Z"
    }
   },
   "id": "24b1f62aaa35c4c4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### global radiation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a925561471d352ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df['grad'].to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.0005],\n",
    "    'model': [ConvNet],\n",
    "    'kernel_sizes': [(12, 6), (10, 10), (6, 12)],\n",
    "    'channels': [(8, 16), (16, 32)],\n",
    "    'noise_sigma': [0.05],\n",
    "    'dropout': [0.5],\n",
    "    'batch_size': [2048],\n",
    "})\n",
    "\n",
    "wrapper: tl.RECOneModelTSWrapper = tl.RECOneModelTSWrapper(ConvNet(), 24, 3)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=2)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de8bb48e37d0fc32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df['grad'].to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [TCN],\n",
    "    'kernel_size': [3, 5],\n",
    "    'num_channels': [(16, 32), (32, 32)],\n",
    "    'noise_sigma': [0.05],\n",
    "    'dropout': [0.5],\n",
    "    'batch_size': [2048],\n",
    "})\n",
    "\n",
    "wrapper: tl.RECOneModelTSWrapper = tl.RECOneModelTSWrapper(TCN(), 24, 3)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=2)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77202b165f34fcb8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df['grad'].to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [LSTMModel, GRUModel],\n",
    "    'features': [1],\n",
    "    'hidden_size': [10, 15, 20],\n",
    "    'num_layers': [2],\n",
    "    'bidirectional': [True],\n",
    "    'hid_noise': [0.05],\n",
    "    'dropout': [0.5],\n",
    "    'batch_size': [2048],\n",
    "})\n",
    "\n",
    "wrapper: tl.RECOneModelTSWrapper = tl.RECOneModelTSWrapper(GRUModel(), 24, 3)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=2)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4da047fd78a33b87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's try external features, will only predict 1 hour ahead here, the MMRec will give us the rest."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f544c8eb404abbf4"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Grid search 001] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'model': <class '__main__.LSTMModel'>, 'features': 10, 'hidden_size': 15, 'num_layers': 2, 'bidirectional': True, 'hid_noise': 0.05, 'dropout': 0.5, 'batch_size': 2048}\n",
      "[Fold 1] BEGIN - END - RMSE loss: 28.758 - Time: 0.8 min.\n",
      "[Fold 2] BEGIN - END - RMSE loss: 9.638 - Time: 1.4 min.\n",
      "[Fold 3] BEGIN - END - RMSE loss: 8.097 - Time: 1.1 min.\n",
      "[Fold 4] BEGIN - END - RMSE loss: 6.651 - Time: 2.4 min.\n",
      "[Fold 5] BEGIN - END - RMSE loss: 7.300 - Time: 1.9 min.\n",
      "[Fold 6] BEGIN - END - RMSE loss: 7.348 - Time: 1.9 min.\n",
      "[Grid search 001] END - Score: 11.29871416 * Without 1st split: 7.806904682982908\n",
      "[Grid search 002] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'model': <class '__main__.GRUModel'>, 'features': 10, 'hidden_size': 15, 'num_layers': 2, 'bidirectional': True, 'hid_noise': 0.05, 'dropout': 0.5, 'batch_size': 2048}\n",
      "[Fold 1] BEGIN - END - RMSE loss: 10.326 - Time: 1.7 min.\n",
      "[Fold 2] BEGIN - END - RMSE loss: 7.790 - Time: 1.7 min.\n",
      "[Fold 3] BEGIN - END - RMSE loss: 7.672 - Time: 1.7 min.\n",
      "[Fold 4] BEGIN - END - RMSE loss: 7.308 - Time: 1.8 min.\n",
      "[Fold 5] BEGIN - END - RMSE loss: 7.046 - Time: 3.0 min.\n",
      "[Fold 6] BEGIN - END - RMSE loss: 6.627 - Time: 3.7 min.\n",
      "[Grid search 002] END - Score: 7.79485472 * Without 1st split: 7.288535690587333\n",
      "[Grid search 003] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'model': <class '__main__.LSTMModel'>, 'features': 10, 'hidden_size': 20, 'num_layers': 2, 'bidirectional': True, 'hid_noise': 0.05, 'dropout': 0.5, 'batch_size': 2048}\n",
      "[Fold 1] BEGIN - END - RMSE loss: 32.009 - Time: 0.8 min.\n",
      "[Fold 2] BEGIN - END - RMSE loss: 7.501 - Time: 1.8 min.\n",
      "[Fold 3] BEGIN - END - RMSE loss: 7.758 - Time: 1.4 min.\n",
      "[Fold 4] BEGIN - END - RMSE loss: 6.729 - Time: 1.9 min.\n",
      "[Fold 5] BEGIN - END - RMSE loss: 7.000 - Time: 1.7 min.\n",
      "[Fold 6] BEGIN - END - RMSE loss: 7.005 - Time: 1.9 min.\n",
      "[Grid search 003] END - Score: 11.33364486 Without 1st split: 7.198557151140686\n",
      "[Grid search 004] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'model': <class '__main__.GRUModel'>, 'features': 10, 'hidden_size': 20, 'num_layers': 2, 'bidirectional': True, 'hid_noise': 0.05, 'dropout': 0.5, 'batch_size': 2048}\n",
      "[Fold 1] BEGIN - END - RMSE loss: 11.063 - Time: 1.3 min.\n",
      "[Fold 2] BEGIN - END - RMSE loss: 7.858 - Time: 1.4 min.\n",
      "[Fold 3] BEGIN - END - RMSE loss: 7.167 - Time: 1.5 min.\n",
      "[Fold 4] BEGIN - END - RMSE loss: 7.429 - Time: 1.3 min.\n",
      "[Fold 5] BEGIN - END - RMSE loss: 6.460 - Time: 2.7 min.\n",
      "[Fold 6] BEGIN - END - RMSE loss: 7.075 - Time: 2.2 min.\n",
      "[Grid search 004] END - Score: 7.84195726 Without 1st split: 7.197727547355562\n",
      "\n",
      "Best params: {'epochs': 1000, 'lr': 0.001, 'model': <class '__main__.GRUModel'>, 'features': 10, 'hidden_size': 15, 'num_layers': 2, 'bidirectional': True, 'hid_noise': 0.05, 'dropout': 0.5, 'batch_size': 2048}\n",
      "Best score: 7.794854718825455\n"
     ]
    }
   ],
   "source": [
    "X = df.to_numpy(dtype=np.float32)[:, 1:] # remove el_load\n",
    "y = df['grad'].to_numpy(dtype=np.float32)\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [LSTMModel, GRUModel],\n",
    "    'features': [10],\n",
    "    'hidden_size': [15, 20],\n",
    "    'num_layers': [2],\n",
    "    'bidirectional': [True],\n",
    "    'hid_noise': [0.05],\n",
    "    'dropout': [0.5],\n",
    "    'batch_size': [2048],\n",
    "})\n",
    "\n",
    "wrapper: tl.MIMOTSWrapper = tl.MIMOTSWrapper(GRUModel(), seq_len=24, pred_len=1)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=3)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T12:01:00.031913400Z",
     "start_time": "2024-01-18T11:17:50.932122Z"
    }
   },
   "id": "6fb0005601954e72"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### el_load non-recursive"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a74195079189303c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = df['el_load'].to_numpy(dtype=np.float32)\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [LSTMModel, GRUModel],\n",
    "    'hidden_size': [15, 25, 35],\n",
    "    'num_layers': [2, 3],\n",
    "    'bidirectional': [True],\n",
    "    'batch_size': [2048],\n",
    "    'dropout': [0.5],\n",
    "    'hid_noise': [0.05],\n",
    "})\n",
    "\n",
    "wrapper: tl.MIMOTSWrapper = tl.MIMOTSWrapper(LSTMModel(), seq_len=24, pred_len=1)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=3)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ced78b5203c0289"
  },
  {
   "cell_type": "markdown",
   "source": [
    "No major differences here, in the first run GRU with 25 hidden size and 2 layers were the best"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c645aca6444d053c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = df['el_load'].to_numpy(dtype=np.float32)\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [LSTMModel, GRUModel],\n",
    "    'hidden_size': [10, 15],\n",
    "    'num_layers': [2],\n",
    "    'bidirectional': [True],\n",
    "    'batch_size': [2048],\n",
    "    'dropout': [0.5],\n",
    "    'hid_noise': [0.05],\n",
    "})\n",
    "\n",
    "wrapper: tl.MIMOTSWrapper = tl.MIMOTSWrapper(LSTMModel(), seq_len=24, pred_len=1)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=3)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be7e8870906e3ee5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "let's try a single layer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ab7212d25b41cda"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = df['el_load'].to_numpy(dtype=np.float32)\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [GRUModel],\n",
    "    'hidden_size': [25, 30, 35],\n",
    "    'num_layers': [1],\n",
    "    'bidirectional': [True],\n",
    "    'batch_size': [2048],\n",
    "    'dropout': [0.5],\n",
    "    'hid_noise': [0.05],\n",
    "    'es_p': [20],\n",
    "})\n",
    "\n",
    "wrapper: tl.MIMOTSWrapper = tl.MIMOTSWrapper(GRUModel(), seq_len=24, pred_len=1)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=3)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4c93943c91919"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = df['el_load'].to_numpy(dtype=np.float32)\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [GRUModel],\n",
    "    'hidden_size': [40, 45],\n",
    "    'num_layers': [1],\n",
    "    'bidirectional': [True],\n",
    "    'batch_size': [2048],\n",
    "    'dropout': [0.5],\n",
    "    'hid_noise': [0.05],\n",
    "    'es_p': [20],\n",
    "})\n",
    "\n",
    "wrapper: tl.MIMOTSWrapper = tl.MIMOTSWrapper(GRUModel(), seq_len=24, pred_len=1)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=3)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdd19ed313306c0f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### putting it all together"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d9233c21ff70f8f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MultiModelRec(nn.Module):\n",
    "    def __init__(self, features=11, pred_len=3, hidden_size=15, num_layers=2, dropout=0.0,\n",
    "                 hid_noise=0.0, bidirectional=True,  **kwargs):\n",
    "        super(MultiModelRec, self).__init__()\n",
    "        self.out_features = 3\n",
    "        self.pred_len = pred_len\n",
    "        \n",
    "        self.gru = GRUModel(features, hidden_size, num_layers, dropout, hid_noise, bidirectional)\n",
    "        self.tcn = TCN((32,) * 2, kernel_size=5, dropout=dropout, hid_noise=hid_noise)\n",
    "        self.conv = ConvNet((16, 32), (6, 12), 0.5, 0.05)\n",
    "\n",
    "\n",
    "    def forward(self, x, y, teacher_forcing=0.0):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        if y.shape[2] != self.gru.gru.input_size:\n",
    "            pre_calc = torch.concat((\n",
    "                torch.zeros(batch_size, self.pred_len, self.out_features).to(tl.TRAINER_LIB_DEVICE),\n",
    "                y), dim=2)\n",
    "            teacher_forcing = 0.0\n",
    "        else:\n",
    "            pre_calc = y\n",
    "\n",
    "        output = torch.zeros(batch_size, self.pred_len).to(tl.TRAINER_LIB_DEVICE)\n",
    "\n",
    "        for i in range(self.pred_len):\n",
    "            out = torch.concat((\n",
    "                self.gru(x),\n",
    "                self.tcn(x[:, :, 1]),\n",
    "                self.conv(x[:, :, 2])\n",
    "            ), dim=1)\n",
    "\n",
    "            output[:, i] = out[:, 0]\n",
    "            \n",
    "            x = torch.cat((x[:, 1:], pre_calc[:, i].unsqueeze(1)), dim=1)\n",
    "            for j in range(self.out_features):  # roll teacher forcing for each feature\n",
    "                if torch.rand(1) > teacher_forcing:\n",
    "                    x[:, -1, j] = out[:, j]\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [MultiModelRec],\n",
    "    'hidden_size': [25, 30, 35],\n",
    "    'num_layers': [2],\n",
    "    'bidirectional': [True],\n",
    "    'batch_size': [1024],\n",
    "    'dropout': [0.5],\n",
    "    'hid_noise': [0.05],\n",
    "    'es_p': [20],\n",
    "})\n",
    "\n",
    "wrap: tl.RECMultiModelTSWrapper = tl.RECMultiModelTSWrapper(MultiModelRec(), 24, 3, 3, teacher_forcing_decay=0.01)\n",
    "b_p, b_s = wrap.grid_search(X, y, grid, verbose=4)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21eda4dd279fe33c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [MultiModelRec],\n",
    "    'hidden_size': [55, 50, 45],\n",
    "    'num_layers': [1],\n",
    "    'bidirectional': [True],\n",
    "    'batch_size': [1024],\n",
    "    'dropout': [0.5],\n",
    "    'hid_noise': [0.05],\n",
    "    'es_p': [25],\n",
    "})\n",
    "\n",
    "wrap: tl.RECMultiModelTSWrapper = tl.RECMultiModelTSWrapper(MultiModelRec(), 24, 3, 3, teacher_forcing_decay=0.01)\n",
    "b_p, b_s = wrap.grid_search(X, y, grid, verbose=4)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90b967ef803762f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### testing MMRec with full feature access"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd02593ce9cdc427"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "class FullMultiModelRec(nn.Module):\n",
    "    def __init__(self, features=11, pred_len=3, hidden_size=15, num_layers=2, dropout=0.0,\n",
    "                 hid_noise=0.0, bidirectional=True,  **kwargs):\n",
    "        super(FullMultiModelRec, self).__init__()\n",
    "        self.out_features = 3\n",
    "        self.pred_len = pred_len\n",
    "        \n",
    "        self.gru = GRUModel(features, hidden_size, num_layers, dropout, hid_noise, bidirectional)\n",
    "        self.ft1 = GRUModel(features-1, 20, 2, dropout, hid_noise, True)\n",
    "        self.ft2 = GRUModel(features-1, 20, 2, dropout, hid_noise, True)\n",
    "\n",
    "\n",
    "    def forward(self, x, y, teacher_forcing=0.0):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        if y.shape[2] != self.gru.gru.input_size:\n",
    "            pre_calc = torch.concat((\n",
    "                torch.zeros(batch_size, self.pred_len, self.out_features).to(tl.TRAINER_LIB_DEVICE),\n",
    "                y), dim=2)\n",
    "            teacher_forcing = 0.0\n",
    "        else:\n",
    "            pre_calc = y\n",
    "\n",
    "        output = torch.zeros(batch_size, self.pred_len).to(tl.TRAINER_LIB_DEVICE)\n",
    "\n",
    "        for i in range(self.pred_len):\n",
    "            out = torch.concat((\n",
    "                self.gru(x),\n",
    "                self.ft1(x[:, :, 1:]),\n",
    "                self.ft2(x[:, :, 1:])\n",
    "            ), dim=1)\n",
    "\n",
    "            output[:, i] = out[:, 0]\n",
    "            \n",
    "            x = torch.cat((x[:, 1:], pre_calc[:, i].unsqueeze(1)), dim=1)\n",
    "            for j in range(self.out_features):  # roll teacher forcing for each feature\n",
    "                if torch.rand(1) > teacher_forcing:\n",
    "                    x[:, -1, j] = out[:, j]\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c3bba851b0de7e4"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Grid search 001] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'model': <class '__main__.FullMultiModelRec'>, 'hidden_size': 25, 'num_layers': 2, 'bidirectional': True, 'batch_size': 1024, 'dropout': 0.5, 'hid_noise': 0.05, 'es_p': 20}\n",
      "[Fold 1] BEGIN\n",
      "Early stopping... Epoch 120: train loss: 0.033296, val loss: 0.033607, test loss: 0.076005\n",
      "[Fold 1] END - RMSE loss: 137.309 - Time: 1.6 min.\n",
      "[Fold 2] BEGIN\n",
      "Early stopping... Epoch 132: train loss: 0.028707, val loss: 0.008406, test loss: 0.013639\n",
      "[Fold 2] END - RMSE loss: 82.663 - Time: 3.2 min.\n",
      "[Fold 3] BEGIN\n",
      "Early stopping... Epoch 181: train loss: 0.021208, val loss: 0.004782, test loss: 0.014034\n",
      "[Fold 3] END - RMSE loss: 83.895 - Time: 6.3 min.\n",
      "[Fold 4] BEGIN\n",
      "Early stopping... Epoch 240: train loss: 0.019898, val loss: 0.020978, test loss: 0.018359\n",
      "[Fold 4] END - RMSE loss: 88.140 - Time: 9.6 min.\n",
      "[Fold 5] BEGIN\n",
      "Early stopping... Epoch 166: train loss: 0.020744, val loss: 0.011809, test loss: 0.019529\n",
      "[Fold 5] END - RMSE loss: 99.280 - Time: 8.2 min.\n",
      "[Fold 6] BEGIN\n",
      "Early stopping... Epoch 207: train loss: 0.020804, val loss: 0.012538, test loss: 0.019298\n",
      "[Fold 6] END - RMSE loss: 100.213 - Time: 12.0 min.\n",
      "[Grid search 001] END - Score: 98.58347828 * Without 1st split: 90.83831543826875\n",
      "[Grid search 002] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'model': <class '__main__.FullMultiModelRec'>, 'hidden_size': 30, 'num_layers': 2, 'bidirectional': True, 'batch_size': 1024, 'dropout': 0.5, 'hid_noise': 0.05, 'es_p': 20}\n",
      "[Fold 1] BEGIN\n",
      "Early stopping... Epoch 130: train loss: 0.028624, val loss: 0.039933, test loss: 0.095998\n",
      "[Fold 1] END - RMSE loss: 143.488 - Time: 1.7 min.\n",
      "[Fold 2] BEGIN\n",
      "Early stopping... Epoch 225: train loss: 0.019953, val loss: 0.006430, test loss: 0.011613\n",
      "[Fold 2] END - RMSE loss: 73.479 - Time: 5.3 min.\n",
      "[Fold 3] BEGIN\n",
      "Early stopping... Epoch 218: train loss: 0.017970, val loss: 0.004837, test loss: 0.015334\n",
      "[Fold 3] END - RMSE loss: 83.402 - Time: 7.3 min.\n",
      "[Fold 4] BEGIN\n",
      "Early stopping... Epoch 243: train loss: 0.016952, val loss: 0.018643, test loss: 0.016679\n",
      "[Fold 4] END - RMSE loss: 82.584 - Time: 10.6 min.\n",
      "[Fold 5] BEGIN\n",
      "Early stopping... Epoch 182: train loss: 0.018265, val loss: 0.011039, test loss: 0.019810\n",
      "[Fold 5] END - RMSE loss: 98.166 - Time: 9.6 min.\n",
      "[Fold 6] BEGIN\n",
      "Early stopping... Epoch 080: train loss: 0.024636, val loss: 0.015140, test loss: 0.024279\n",
      "[Fold 6] END - RMSE loss: 113.054 - Time: 5.0 min.\n",
      "[Grid search 002] END - Score: 99.02878763 Without 1st split: 90.1369584229183\n",
      "[Grid search 003] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'model': <class '__main__.FullMultiModelRec'>, 'hidden_size': 35, 'num_layers': 2, 'bidirectional': True, 'batch_size': 1024, 'dropout': 0.5, 'hid_noise': 0.05, 'es_p': 20}\n",
      "[Fold 1] BEGIN\n",
      "Early stopping... Epoch 092: train loss: 0.029834, val loss: 0.025319, test loss: 0.056310\n",
      "[Fold 1] END - RMSE loss: 135.082 - Time: 1.6 min.\n",
      "[Fold 2] BEGIN\n",
      "Early stopping... Epoch 100: train loss: 0.026540, val loss: 0.008427, test loss: 0.014961\n",
      "[Fold 2] END - RMSE loss: 89.002 - Time: 2.7 min.\n",
      "[Fold 3] BEGIN\n",
      "Early stopping... Epoch 188: train loss: 0.017691, val loss: 0.004675, test loss: 0.013888\n",
      "[Fold 3] END - RMSE loss: 81.602 - Time: 7.2 min.\n",
      "[Fold 4] BEGIN\n",
      "Early stopping... Epoch 089: train loss: 0.023253, val loss: 0.028455, test loss: 0.028294\n",
      "[Fold 4] END - RMSE loss: 110.181 - Time: 4.4 min.\n",
      "[Fold 5] BEGIN\n",
      "\tEpoch 004: train loss: 0.065250, val loss: 0.044765, test loss: 0.063130  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 59\u001B[0m\n\u001B[0;32m     45\u001B[0m grid \u001B[38;5;241m=\u001B[39m tl\u001B[38;5;241m.\u001B[39mGrid({\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepochs\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m1000\u001B[39m],  \u001B[38;5;66;03m# we use early stopping, so this is just a high number\u001B[39;00m\n\u001B[0;32m     47\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m0.001\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     55\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mes_p\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m20\u001B[39m],\n\u001B[0;32m     56\u001B[0m })\n\u001B[0;32m     58\u001B[0m wrap: tl\u001B[38;5;241m.\u001B[39mRECMultiModelTSWrapper \u001B[38;5;241m=\u001B[39m tl\u001B[38;5;241m.\u001B[39mRECMultiModelTSWrapper(FullMultiModelRec(), \u001B[38;5;241m24\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m3\u001B[39m, teacher_forcing_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m---> 59\u001B[0m b_p, b_s \u001B[38;5;241m=\u001B[39m \u001B[43mwrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrid_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mBest params: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mb_p\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mBest score: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mb_s\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Desktop\\Python\\TimeSeries\\es_load_fs_HUN\\models\\trainer_lib.py:514\u001B[0m, in \u001B[0;36mTSMWrapper.grid_search\u001B[1;34m(self, x, y, g, loss_fn, verbose)\u001B[0m\n\u001B[0;32m    510\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Grid search \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] BEGIN\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    511\u001B[0m           end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m - params: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparams\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m verbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    513\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setup_strategy(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[1;32m--> 514\u001B[0m _, _, _, metric_losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidate_ts_strategy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    516\u001B[0m score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(metric_losses) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(metric_losses)\n\u001B[0;32m    517\u001B[0m score_no_1st \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(metric_losses[\u001B[38;5;241m1\u001B[39m:]) \u001B[38;5;241m/\u001B[39m (\u001B[38;5;28mlen\u001B[39m(metric_losses) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\Desktop\\Python\\TimeSeries\\es_load_fs_HUN\\models\\trainer_lib.py:476\u001B[0m, in \u001B[0;36mTSMWrapper.validate_ts_strategy\u001B[1;34m(self, x, y, epochs, loss_fn, val_mod, lr, batch_size, es_p, es_d, n_splits, verbose, cp, **kwargs)\u001B[0m\n\u001B[0;32m    473\u001B[0m y_train, y_val, y_test \u001B[38;5;241m=\u001B[39m y[train_idxs], y[val_idxs], y[test_idxs]\n\u001B[0;32m    475\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_strategy()\n\u001B[1;32m--> 476\u001B[0m train_loss, val_loss, test_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_strategy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    477\u001B[0m \u001B[43m                                                      \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    478\u001B[0m \u001B[43m                                                      \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mes_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mes_p\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mes_d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mes_d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    479\u001B[0m \u001B[43m                                                      \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    481\u001B[0m pred, true \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(x_test, y_test)\n\u001B[0;32m    482\u001B[0m metric_loss \u001B[38;5;241m=\u001B[39m math_sqrt(nn\u001B[38;5;241m.\u001B[39mMSELoss()(torch\u001B[38;5;241m.\u001B[39mtensor(pred), torch\u001B[38;5;241m.\u001B[39mtensor(true))\u001B[38;5;241m.\u001B[39mitem())\n",
      "File \u001B[1;32m~\\Desktop\\Python\\TimeSeries\\es_load_fs_HUN\\models\\trainer_lib.py:813\u001B[0m, in \u001B[0;36mMIMOTSWrapper.train_strategy\u001B[1;34m(self, x_train, y_train, x_val, y_val, x_test, y_test, epochs, lr, optimizer, batch_size, loss_fn, es_p, es_d, verbose, cp, **kwargs)\u001B[0m\n\u001B[0;32m    810\u001B[0m     test_dataset: Dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_ts_dataset(x_test, y_test)\n\u001B[0;32m    811\u001B[0m     test_loader: DataLoader \u001B[38;5;241m=\u001B[39m DataLoader(test_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m--> 813\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    814\u001B[0m \u001B[43m                         \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mes_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mes_p\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mes_d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mes_d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    815\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcp\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Python\\TimeSeries\\es_load_fs_HUN\\models\\trainer_lib.py:369\u001B[0m, in \u001B[0;36mTSMWrapper._train_model\u001B[1;34m(self, train_loader, val_loader, test_loader, epochs, lr, optimizer, loss_fn, es_p, es_d, verbose, cp)\u001B[0m\n\u001B[0;32m    367\u001B[0m early_stopper \u001B[38;5;241m=\u001B[39m EarlyStopper(patience\u001B[38;5;241m=\u001B[39mes_p, min_delta\u001B[38;5;241m=\u001B[39mes_d, model\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m cp \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model)\n\u001B[0;32m    368\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m--> 369\u001B[0m     train_loss: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    370\u001B[0m     train_losses\u001B[38;5;241m.\u001B[39mappend(train_loss)\n\u001B[0;32m    372\u001B[0m     val_loss: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_test_model(val_loader, loss_fn\u001B[38;5;241m=\u001B[39mloss_fn)\n",
      "File \u001B[1;32m~\\Desktop\\Python\\TimeSeries\\es_load_fs_HUN\\models\\trainer_lib.py:1012\u001B[0m, in \u001B[0;36mRECMultiModelTSWrapper._train_epoch\u001B[1;34m(self, data_loader, lr, optimizer, loss_fn)\u001B[0m\n\u001B[0;32m   1009\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(TRAINER_LIB_DEVICE)\n\u001B[0;32m   1011\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m-> 1012\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_teacher_forcing\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1013\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(outputs, labels[:, :, \u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m   1014\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[12], line 29\u001B[0m, in \u001B[0;36mFullMultiModelRec.forward\u001B[1;34m(self, x, y, teacher_forcing)\u001B[0m\n\u001B[0;32m     24\u001B[0m output \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(batch_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpred_len)\u001B[38;5;241m.\u001B[39mto(tl\u001B[38;5;241m.\u001B[39mTRAINER_LIB_DEVICE)\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpred_len):\n\u001B[0;32m     27\u001B[0m     out \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mconcat((\n\u001B[0;32m     28\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgru(x),\n\u001B[1;32m---> 29\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mft1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m     30\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mft2(x[:, :, \u001B[38;5;241m1\u001B[39m:])\n\u001B[0;32m     31\u001B[0m     ), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     33\u001B[0m     output[:, i] \u001B[38;5;241m=\u001B[39m out[:, \u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     35\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((x[:, \u001B[38;5;241m1\u001B[39m:], pre_calc[:, i]\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m)), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[3], line 51\u001B[0m, in \u001B[0;36mGRUModel.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m     50\u001B[0m     batch_size \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m---> 51\u001B[0m     hidden \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzeros\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mh_n_dim\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhidden_size\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTRAINER_LIB_DEVICE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m     output, hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgru(x, hidden)\n\u001B[0;32m     55\u001B[0m     hidden \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mpermute(hidden, (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m))\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [FullMultiModelRec],\n",
    "    'hidden_size': [25, 30, 35],\n",
    "    'num_layers': [2],\n",
    "    'bidirectional': [True],\n",
    "    'batch_size': [1024],\n",
    "    'dropout': [0.5],\n",
    "    'hid_noise': [0.05],\n",
    "    'es_p': [20],\n",
    "})\n",
    "\n",
    "wrap: tl.RECMultiModelTSWrapper = tl.RECMultiModelTSWrapper(FullMultiModelRec(), 24, 3, 3, teacher_forcing_decay=0.01)\n",
    "b_p, b_s = wrap.grid_search(X, y, grid, verbose=4)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-18T12:05:25.834645600Z"
    }
   },
   "id": "1677d7bd765c0170"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Grid search 001] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'model': <class '__main__.FullMultiModelRec'>, 'hidden_size': 40, 'num_layers': 1, 'bidirectional': True, 'batch_size': 1024, 'dropout': 0.5, 'hid_noise': 0.05, 'es_p': 25}\n",
      "[Fold 1] BEGIN\n",
      "Early stopping... Epoch 127: train loss: 0.032839, val loss: 0.025279, test loss: 0.049995\n",
      "[Fold 1] END - RMSE loss: 135.489 - Time: 1.6 min.\n",
      "[Fold 2] BEGIN\n",
      "Early stopping... Epoch 179: train loss: 0.025955, val loss: 0.008902, test loss: 0.015419\n",
      "[Fold 2] END - RMSE loss: 85.133 - Time: 3.5 min.\n",
      "[Fold 3] BEGIN\n",
      "Early stopping... Epoch 298: train loss: 0.020169, val loss: 0.004430, test loss: 0.015255\n",
      "[Fold 3] END - RMSE loss: 84.560 - Time: 8.4 min.\n",
      "[Fold 4] BEGIN\n",
      "Early stopping... Epoch 168: train loss: 0.022933, val loss: 0.020945, test loss: 0.017838\n",
      "[Fold 4] END - RMSE loss: 94.099 - Time: 6.4 min.\n",
      "[Fold 5] BEGIN\n",
      "Early stopping... Epoch 224: train loss: 0.021980, val loss: 0.011119, test loss: 0.019803\n",
      "[Fold 5] END - RMSE loss: 98.655 - Time: 11.0 min.\n",
      "[Fold 6] BEGIN\n",
      "Early stopping... Epoch 214: train loss: 0.021968, val loss: 0.013057, test loss: 0.019738\n",
      "[Fold 6] END - RMSE loss: 101.187 - Time: 12.4 min.\n",
      "[Grid search 001] END - Score: 99.85381887 * Without 1st split: 92.7267434140799\n",
      "[Grid search 002] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'model': <class '__main__.FullMultiModelRec'>, 'hidden_size': 45, 'num_layers': 1, 'bidirectional': True, 'batch_size': 1024, 'dropout': 0.5, 'hid_noise': 0.05, 'es_p': 25}\n",
      "[Fold 1] BEGIN\n",
      "Early stopping... Epoch 129: train loss: 0.029350, val loss: 0.023874, test loss: 0.046468\n",
      "[Fold 1] END - RMSE loss: 145.944 - Time: 1.9 min.\n",
      "[Fold 2] BEGIN\n",
      "Early stopping... Epoch 107: train loss: 0.028996, val loss: 0.010050, test loss: 0.016756\n",
      "[Fold 2] END - RMSE loss: 89.336 - Time: 2.3 min.\n",
      "[Fold 3] BEGIN\n",
      "Early stopping... Epoch 199: train loss: 0.019634, val loss: 0.005847, test loss: 0.016236\n",
      "[Fold 3] END - RMSE loss: 83.265 - Time: 6.2 min.\n",
      "[Fold 4] BEGIN\n",
      "Early stopping... Epoch 227: train loss: 0.019747, val loss: 0.020532, test loss: 0.016674\n",
      "[Fold 4] END - RMSE loss: 90.594 - Time: 9.5 min.\n",
      "[Fold 5] BEGIN\n",
      "Early stopping... Epoch 241: train loss: 0.019663, val loss: 0.009551, test loss: 0.018269\n",
      "[Fold 5] END - RMSE loss: 95.205 - Time: 11.3 min.\n",
      "[Fold 6] BEGIN\n",
      "Early stopping... Epoch 184: train loss: 0.020607, val loss: 0.011873, test loss: 0.020487\n",
      "[Fold 6] END - RMSE loss: 98.913 - Time: 10.2 min.\n",
      "[Grid search 002] END - Score: 100.54308302 Without 1st split: 91.46279976259338\n",
      "[Grid search 003] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'model': <class '__main__.FullMultiModelRec'>, 'hidden_size': 50, 'num_layers': 1, 'bidirectional': True, 'batch_size': 1024, 'dropout': 0.5, 'hid_noise': 0.05, 'es_p': 25}\n",
      "[Fold 1] BEGIN\n",
      "Early stopping... Epoch 098: train loss: 0.030697, val loss: 0.020653, test loss: 0.045041\n",
      "[Fold 1] END - RMSE loss: 149.928 - Time: 1.3 min.\n",
      "[Fold 2] BEGIN\n",
      "Early stopping... Epoch 122: train loss: 0.025558, val loss: 0.008833, test loss: 0.016285\n",
      "[Fold 2] END - RMSE loss: 85.639 - Time: 2.7 min.\n",
      "[Fold 3] BEGIN\n",
      "Early stopping... Epoch 186: train loss: 0.019382, val loss: 0.005048, test loss: 0.016389\n",
      "[Fold 3] END - RMSE loss: 88.390 - Time: 5.8 min.\n",
      "[Fold 4] BEGIN\n",
      "Early stopping... Epoch 137: train loss: 0.021192, val loss: 0.027235, test loss: 0.023349\n",
      "[Fold 4] END - RMSE loss: 98.993 - Time: 5.6 min.\n",
      "[Fold 5] BEGIN\n",
      "Early stopping... Epoch 254: train loss: 0.019593, val loss: 0.010833, test loss: 0.020215\n",
      "[Fold 5] END - RMSE loss: 97.312 - Time: 12.7 min.\n",
      "[Fold 6] BEGIN\n",
      "Early stopping... Epoch 075: train loss: 0.024591, val loss: 0.018115, test loss: 0.031132\n",
      "[Fold 6] END - RMSE loss: 118.368 - Time: 4.7 min.\n",
      "[Grid search 003] END - Score: 106.43842694 Without 1st split: 97.74053506509138\n",
      "\n",
      "Best params: {'epochs': 1000, 'lr': 0.001, 'model': <class '__main__.FullMultiModelRec'>, 'hidden_size': 40, 'num_layers': 1, 'bidirectional': True, 'batch_size': 1024, 'dropout': 0.5, 'hid_noise': 0.05, 'es_p': 25}\n",
      "Best score: 99.85381886530104\n"
     ]
    }
   ],
   "source": [
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = X.copy()\n",
    "\n",
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'model': [FullMultiModelRec],\n",
    "    'hidden_size': [40, 45, 50],\n",
    "    'num_layers': [1],\n",
    "    'bidirectional': [True],\n",
    "    'batch_size': [1024],\n",
    "    'dropout': [0.5],\n",
    "    'hid_noise': [0.05],\n",
    "    'es_p': [25],\n",
    "})\n",
    "\n",
    "wrap: tl.RECMultiModelTSWrapper = tl.RECMultiModelTSWrapper(FullMultiModelRec(), 24, 3, 3, teacher_forcing_decay=0.01)\n",
    "b_p, b_s = wrap.grid_search(X, y, grid, verbose=4)\n",
    "print(f\"\\nBest params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T17:49:44.355401900Z",
     "start_time": "2024-01-18T15:52:02.937193600Z"
    }
   },
   "id": "a3272d18e73ea671"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
