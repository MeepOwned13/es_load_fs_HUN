{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1173e19089d7b08"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import trainer_lib as tl\n",
    "\n",
    "torch.manual_seed(310231551)\n",
    "random.seed(3009231410)\n",
    "np.random.seed(2909231846)\n",
    "np_random_state = np.random.RandomState(131002)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T15:00:43.221463700Z",
     "start_time": "2023-10-03T15:00:40.566711800Z"
    }
   },
   "id": "242f902e948b817f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9368fad7ca0a9df2"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75960, 11)\n"
     ]
    }
   ],
   "source": [
    "df: pd.DataFrame = tl.load_country_wide_dataset('../data/country_data.csv')\n",
    "\n",
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = df['el_load'].to_numpy(dtype=np.float32)\n",
    "\n",
    "print(X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T15:00:43.399384Z",
     "start_time": "2023-10-03T15:00:43.222464800Z"
    }
   },
   "id": "6203873f30ffdfa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a90fabd53d08648"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, features=11, hidden_size=15, num_layers=2, bidirectional=True):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.h_n_dim = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size=features, hidden_size=self.hidden_size, num_layers=num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.hidden_size * self.h_n_dim * self.num_layers, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h_0 = torch.zeros(self.h_n_dim * self.num_layers, batch_size, self.hidden_size).requires_grad_().to(tl.TRAINER_LIB_DEVICE)\n",
    "        c_0 = torch.zeros(self.h_n_dim * self.num_layers, batch_size, self.hidden_size).requires_grad_().to(tl.TRAINER_LIB_DEVICE)\n",
    "\n",
    "        output, (h_n, c_n) = self.lstm(x, (h_0, c_0))\n",
    "        h_n = torch.permute(h_n, (1, 0, 2)) # From shape [h_n_dim, batch, hidden_size] -> [batch, h_n_dim, hidden_size]\n",
    "                                            # flatten and fully connected layer expects batch to be the first dimension\n",
    "        return self.fc(h_n)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T15:02:43.309843300Z",
     "start_time": "2023-10-03T15:02:43.307011Z"
    }
   },
   "id": "dcdf8355f27d18f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grid search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7c2907dd02a6611"
  },
  {
   "cell_type": "markdown",
   "source": [
    "I'll first look at different model constructions, then I'll look into hyperparameters, dropouts, noise and maybe higher sequence lengths."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ed6b4ef2243c140"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Grid search 001] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'hidden_size': 15, 'num_layers': 1, 'bidirectional': False, 'n_splits': 6}\n",
      "[Fold 1] BEGIN\n",
      "Early stopping... Epoch 152: train loss: 0.003689, val loss: 0.048384, test loss: 0.045673\n",
      "[Fold 1] END - RMSE loss: 146.754 - Time: 1.5 min.\n",
      "[Fold 2] BEGIN\n",
      "Early stopping... Epoch 031: train loss: 0.009497, val loss: 0.028678, test loss: 0.030876\n",
      "[Fold 2] END - RMSE loss: 102.948 - Time: 0.5 min.\n",
      "[Fold 3] BEGIN\n",
      "Early stopping... Epoch 084: train loss: 0.004522, val loss: 0.017538, test loss: 0.007031\n",
      "[Fold 3] END - RMSE loss: 60.133 - Time: 1.9 min.\n",
      "[Fold 4] BEGIN\n",
      "Early stopping... Epoch 095: train loss: 0.004587, val loss: 0.019779, test loss: 0.016760\n",
      "[Fold 4] END - RMSE loss: 92.231 - Time: 2.8 min.\n",
      "[Fold 5] BEGIN\n",
      "Early stopping... Epoch 032: train loss: 0.007409, val loss: 0.025110, test loss: 0.023704\n",
      "[Fold 5] END - RMSE loss: 111.279 - Time: 1.2 min.\n",
      "[Fold 6] BEGIN\n",
      "Early stopping... Epoch 043: train loss: 0.007017, val loss: 0.025339, test loss: 0.024816\n",
      "[Fold 6] END - RMSE loss: 118.494 - Time: 1.8 min.\n",
      "[Grid search 001] END - Score: 105.30643574 *\n",
      "[Grid search 002] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'hidden_size': 30, 'num_layers': 1, 'bidirectional': False, 'n_splits': 6}\n",
      "[Fold 1] BEGIN\n",
      "Early stopping... Epoch 125: train loss: 0.004295, val loss: 0.034843, test loss: 0.030671\n",
      "[Fold 1] END - RMSE loss: 129.747 - Time: 1.2 min.\n",
      "[Fold 2] BEGIN\n",
      "Early stopping... Epoch 067: train loss: 0.006327, val loss: 0.019704, test loss: 0.024349\n",
      "[Fold 2] END - RMSE loss: 108.232 - Time: 1.1 min.\n",
      "[Fold 3] BEGIN\n",
      "Early stopping... Epoch 062: train loss: 0.005155, val loss: 0.016712, test loss: 0.006797\n",
      "[Fold 3] END - RMSE loss: 58.818 - Time: 1.4 min.\n",
      "[Fold 4] BEGIN\n",
      "Early stopping... Epoch 102: train loss: 0.004295, val loss: 0.014579, test loss: 0.014701\n",
      "[Fold 4] END - RMSE loss: 87.513 - Time: 3.0 min.\n",
      "[Fold 5] BEGIN\n",
      "Early stopping... Epoch 043: train loss: 0.006721, val loss: 0.020018, test loss: 0.023734\n",
      "[Fold 5] END - RMSE loss: 109.364 - Time: 1.5 min.\n",
      "[Fold 6] BEGIN\n",
      "Early stopping... Epoch 032: train loss: 0.007664, val loss: 0.026257, test loss: 0.025551\n",
      "[Fold 6] END - RMSE loss: 114.431 - Time: 1.4 min.\n",
      "[Grid search 002] END - Score: 101.35092730 *\n",
      "[Grid search 003] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'hidden_size': 15, 'num_layers': 2, 'bidirectional': False, 'n_splits': 6}\n",
      "[Fold 1] BEGIN\n",
      "Early stopping... Epoch 130: train loss: 0.004567, val loss: 0.042979, test loss: 0.022552\n",
      "[Fold 1] END - RMSE loss: 111.895 - Time: 1.2 min.\n",
      "[Fold 2] BEGIN\n",
      "Early stopping... Epoch 099: train loss: 0.004831, val loss: 0.012910, test loss: 0.011548\n",
      "[Fold 2] END - RMSE loss: 77.446 - Time: 1.6 min.\n",
      "[Fold 3] BEGIN\n",
      "Early stopping... Epoch 043: train loss: 0.006494, val loss: 0.024442, test loss: 0.009721\n",
      "[Fold 3] END - RMSE loss: 79.558 - Time: 1.0 min.\n",
      "[Fold 4] BEGIN\n",
      "Early stopping... Epoch 078: train loss: 0.005064, val loss: 0.018524, test loss: 0.014954\n",
      "[Fold 4] END - RMSE loss: 91.861 - Time: 2.3 min.\n",
      "[Fold 5] BEGIN\n",
      "Early stopping... Epoch 053: train loss: 0.005944, val loss: 0.022423, test loss: 0.029611\n",
      "[Fold 5] END - RMSE loss: 119.766 - Time: 1.9 min.\n",
      "[Fold 6] BEGIN\n",
      "Early stopping... Epoch 051: train loss: 0.006486, val loss: 0.020183, test loss: 0.020278\n",
      "[Fold 6] END - RMSE loss: 105.339 - Time: 2.1 min.\n",
      "[Grid search 003] END - Score: 97.64409847 *\n",
      "[Grid search 004] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'hidden_size': 30, 'num_layers': 2, 'bidirectional': False, 'n_splits': 6}\n",
      "[Fold 1] BEGIN\n",
      "Early stopping... Epoch 022: train loss: 0.015903, val loss: 0.106977, test loss: 0.167409\n",
      "[Fold 1] END - RMSE loss: 250.116 - Time: 0.2 min.\n",
      "[Fold 2] BEGIN\n",
      "Early stopping... Epoch 099: train loss: 0.004703, val loss: 0.014249, test loss: 0.020229\n",
      "[Fold 2] END - RMSE loss: 96.926 - Time: 1.6 min.\n",
      "[Fold 3] BEGIN\n",
      "Early stopping... Epoch 022: train loss: 0.010502, val loss: 0.047204, test loss: 0.013944\n",
      "[Fold 3] END - RMSE loss: 97.149 - Time: 0.5 min.\n",
      "[Fold 4] BEGIN\n",
      "Early stopping... Epoch 044: train loss: 0.006201, val loss: 0.020562, test loss: 0.014168\n",
      "[Fold 4] END - RMSE loss: 91.840 - Time: 1.3 min.\n",
      "[Fold 5] BEGIN\n",
      "Early stopping... Epoch 053: train loss: 0.005915, val loss: 0.017828, test loss: 0.022286\n",
      "[Fold 5] END - RMSE loss: 110.772 - Time: 1.9 min.\n",
      "[Fold 6] BEGIN\n",
      "Early stopping... Epoch 050: train loss: 0.006745, val loss: 0.022559, test loss: 0.024853\n",
      "[Fold 6] END - RMSE loss: 116.137 - Time: 2.1 min.\n",
      "[Grid search 004] END - Score: 127.15677340 \n",
      "[Grid search 005] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'hidden_size': 15, 'num_layers': 1, 'bidirectional': True, 'n_splits': 6}\n",
      "[Fold 1] BEGIN\n",
      "Early stopping... Epoch 028: train loss: 0.015393, val loss: 0.098028, test loss: 0.128098\n",
      "[Fold 1] END - RMSE loss: 246.339 - Time: 0.3 min.\n",
      "[Fold 2] BEGIN\n",
      "Early stopping... Epoch 116: train loss: 0.004254, val loss: 0.012330, test loss: 0.010686\n",
      "[Fold 2] END - RMSE loss: 77.623 - Time: 1.8 min.\n",
      "[Fold 3] BEGIN\n",
      "Early stopping... Epoch 083: train loss: 0.004500, val loss: 0.012696, test loss: 0.007397\n",
      "[Fold 3] END - RMSE loss: 60.272 - Time: 1.9 min.\n",
      "[Fold 4] BEGIN\n",
      "Early stopping... Epoch 084: train loss: 0.004763, val loss: 0.023674, test loss: 0.016744\n",
      "[Fold 4] END - RMSE loss: 89.179 - Time: 2.5 min.\n",
      "[Fold 5] BEGIN\n",
      "Early stopping... Epoch 042: train loss: 0.006793, val loss: 0.021390, test loss: 0.020927\n",
      "[Fold 5] END - RMSE loss: 108.396 - Time: 1.5 min.\n",
      "[Fold 6] BEGIN\n",
      "Early stopping... Epoch 031: train loss: 0.008376, val loss: 0.029966, test loss: 0.027166\n",
      "[Fold 6] END - RMSE loss: 122.249 - Time: 1.3 min.\n",
      "[Grid search 005] END - Score: 117.34295726 \n",
      "[Grid search 006] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'hidden_size': 30, 'num_layers': 1, 'bidirectional': True, 'n_splits': 6}\n",
      "[Fold 1] BEGIN\n",
      "Early stopping... Epoch 023: train loss: 0.015858, val loss: 0.102933, test loss: 0.120327\n",
      "[Fold 1] END - RMSE loss: 235.147 - Time: 0.2 min.\n",
      "[Fold 2] BEGIN\n",
      "Early stopping... Epoch 127: train loss: 0.003945, val loss: 0.014432, test loss: 0.012829\n",
      "[Fold 2] END - RMSE loss: 80.482 - Time: 2.0 min.\n",
      "[Fold 3] BEGIN\n",
      "Early stopping... Epoch 056: train loss: 0.005576, val loss: 0.022978, test loss: 0.009389\n",
      "[Fold 3] END - RMSE loss: 68.798 - Time: 1.3 min.\n",
      "[Fold 4] BEGIN\n",
      "Early stopping... Epoch 078: train loss: 0.004793, val loss: 0.015315, test loss: 0.015114\n",
      "[Fold 4] END - RMSE loss: 90.205 - Time: 2.3 min.\n",
      "[Fold 5] BEGIN\n",
      "Early stopping... Epoch 042: train loss: 0.006865, val loss: 0.023488, test loss: 0.025438\n",
      "[Fold 5] END - RMSE loss: 124.383 - Time: 1.5 min.\n",
      "[Fold 6] BEGIN\n",
      "Early stopping... Epoch 055: train loss: 0.006267, val loss: 0.031724, test loss: 0.028780\n",
      "[Fold 6] END - RMSE loss: 126.110 - Time: 2.4 min.\n",
      "[Grid search 006] END - Score: 120.85396712 \n",
      "[Grid search 007] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'hidden_size': 15, 'num_layers': 2, 'bidirectional': True, 'n_splits': 6}\n",
      "[Fold 1] BEGIN\n",
      "Early stopping... Epoch 086: train loss: 0.005644, val loss: 0.052843, test loss: 0.050031\n",
      "[Fold 1] END - RMSE loss: 154.402 - Time: 0.8 min.\n",
      "[Fold 2] BEGIN\n",
      "Early stopping... Epoch 078: train loss: 0.005129, val loss: 0.016879, test loss: 0.018439\n",
      "[Fold 2] END - RMSE loss: 94.801 - Time: 1.2 min.\n",
      "[Fold 3] BEGIN\n",
      "Early stopping... Epoch 041: train loss: 0.006618, val loss: 0.022093, test loss: 0.011187\n",
      "[Fold 3] END - RMSE loss: 68.422 - Time: 0.9 min.\n",
      "[Fold 4] BEGIN\n",
      "Early stopping... Epoch 071: train loss: 0.005119, val loss: 0.023237, test loss: 0.018502\n",
      "[Fold 4] END - RMSE loss: 91.398 - Time: 2.1 min.\n",
      "[Fold 5] BEGIN\n",
      "Early stopping... Epoch 072: train loss: 0.005178, val loss: 0.019911, test loss: 0.019077\n",
      "[Fold 5] END - RMSE loss: 102.959 - Time: 2.6 min.\n",
      "[Fold 6] BEGIN\n",
      "Early stopping... Epoch 025: train loss: 0.008806, val loss: 0.028133, test loss: 0.024242\n",
      "[Fold 6] END - RMSE loss: 121.943 - Time: 1.0 min.\n",
      "[Grid search 007] END - Score: 105.65434928 \n",
      "[Grid search 008] BEGIN - params: {'epochs': 1000, 'lr': 0.001, 'hidden_size': 30, 'num_layers': 2, 'bidirectional': True, 'n_splits': 6}\n",
      "[Fold 1] BEGIN\n",
      "Early stopping... Epoch 031: train loss: 0.012148, val loss: 0.079918, test loss: 0.089523\n",
      "[Fold 1] END - RMSE loss: 213.125 - Time: 0.3 min.\n",
      "[Fold 2] BEGIN\n",
      "Early stopping... Epoch 065: train loss: 0.006317, val loss: 0.017142, test loss: 0.019713\n",
      "[Fold 2] END - RMSE loss: 96.351 - Time: 1.0 min.\n",
      "[Fold 3] BEGIN\n",
      "Early stopping... Epoch 075: train loss: 0.005048, val loss: 0.029421, test loss: 0.008602\n",
      "[Fold 3] END - RMSE loss: 66.509 - Time: 1.7 min.\n",
      "[Fold 4] BEGIN\n",
      "Early stopping... Epoch 048: train loss: 0.006004, val loss: 0.021995, test loss: 0.018204\n",
      "[Fold 4] END - RMSE loss: 94.400 - Time: 1.4 min.\n",
      "[Fold 5] BEGIN\n",
      "Early stopping... Epoch 037: train loss: 0.007067, val loss: 0.022765, test loss: 0.030374\n",
      "[Fold 5] END - RMSE loss: 121.745 - Time: 1.3 min.\n",
      "[Fold 6] BEGIN\n",
      "Early stopping... Epoch 048: train loss: 0.006552, val loss: 0.025318, test loss: 0.026408\n",
      "[Fold 6] END - RMSE loss: 113.860 - Time: 2.1 min.\n",
      "[Grid search 008] END - Score: 117.66507706 \n",
      "Best params: {'epochs': 1000, 'lr': 0.001, 'hidden_size': 15, 'num_layers': 2, 'bidirectional': False, 'n_splits': 6}\n",
      "Best score: 97.64409846721132\n"
     ]
    }
   ],
   "source": [
    "grid = tl.Grid({\n",
    "    'epochs': [1000],  # we use early stopping, so this is just a high number\n",
    "    'lr': [0.001],\n",
    "    'hidden_size': [15, 30],\n",
    "    'num_layers': [1, 2],\n",
    "    'bidirectional': [False, True],\n",
    "    'n_splits': [6],\n",
    "})\n",
    "\n",
    "wrapper = tl.MIMOTSWrapper(LSTMModel(), seq_len=24, pred_len=3)\n",
    "b_p, b_s = wrapper.grid_search(X, y, grid, verbose=4)\n",
    "print(f\"Best params: {b_p}\\nBest score: {b_s}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T16:15:10.118467700Z",
     "start_time": "2023-10-03T15:02:44.537720800Z"
    }
   },
   "id": "f7c94fa75f614a23"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
