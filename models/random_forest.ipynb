{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eebf5f152872d283"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from trainer_lib import load_country_wide_dataset, TSMWrapper\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, cross_val_score\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "import os\n",
    "\n",
    "np.random.seed(2909231846)\n",
    "randomstate = np.random.RandomState(131002)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13a1460cfaa9c09d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df: pd.DataFrame = load_country_wide_dataset('../data/country_data.csv')\n",
    "\n",
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = df['el_load'].to_numpy(dtype=np.float32)\n",
    "rf_X = np.zeros((len(X)-24-3, 24*X.shape[1]))\n",
    "rf_y = np.zeros((len(X)-24-3, 3))\n",
    "for i in range(len(X)-24-3):\n",
    "    rf_X[i] = X[i:i+24].flatten()\n",
    "    rf_y[i] = y[i+24:i+24+3]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e003afbad9fd2a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grid search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e193fe77f23b869"
  },
  {
   "cell_type": "markdown",
   "source": [
    "I'll first use grid search to get an idea of how to tune the parameters, then I'll go ahead and define some myself."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4726d245632d5ca7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_cpu = os.cpu_count()\n",
    "print(f\"Number of CPUs in the system: {n_cpu}, n_jobs will be set to {n_cpu-2}\")\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=6)\n",
    "split = tscv.split(rf_X, rf_y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6656aca522988f95"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [150, 300],\n",
    "    'max_depth': [5, 15],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'max_features': ['log2', 'sqrt', 0.5],\n",
    "}\n",
    "# Fitting 6 folds for each of 24 candidates, totalling 144 fits\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=randomstate, n_jobs=n_cpu-2),\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    param_grid=param_grid,\n",
    "    cv=split,\n",
    "    verbose=4,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "results = grid_search.fit(rf_X, rf_y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c16b357ba37642a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Best parameters: {results.best_params_}\")\n",
    "print(f\"Best score: {results.best_score_}\")\n",
    "\n",
    "# Best parameters: {'max_depth': 15, 'max_features': 0.5, 'min_samples_split': 2, 'n_estimators': 300}\n",
    "# Best score: -106.06095301049247"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cb6c90873d77e0e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Estimator number tuning and train size limit"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "853537b57dd760cb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "300 estimators only barely score better, it might be worth using less.\n",
    "The models seem to fit worse and worse as the trainig data size increases past the 2nd fold, let's try to limit it. Maybe we are looking too far into the past."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b026bb4eb49949f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=6, max_train_size=rf_X.shape[0]//3)\n",
    "split = tscv.split(rf_X, rf_y)\n",
    "\n",
    "score = cross_val_score(\n",
    "    RandomForestRegressor(random_state=randomstate, n_jobs=n_cpu-2, max_depth=15, max_features=0.5, min_samples_split=2, n_estimators=150),\n",
    "    rf_X, rf_y,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=split,\n",
    "    verbose=4,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e511f536d81c60c3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is mild improvement, but not much, I still want to test less estimators and maybe bring back the covid column."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c520e3001696ae11"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Covid column"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3bbd708d20c5413"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['covid'] = 0\n",
    "df.loc['2020-03-11 00:00:00':'2022-03-7 23:00:00', 'covid'] = 1\n",
    "df['covid'] = df['covid'].astype(float)\n",
    "\n",
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = df['el_load'].to_numpy(dtype=np.float32)\n",
    "rf_X = np.zeros((len(X)-24-3, 24*X.shape[1]))\n",
    "rf_y = np.zeros((len(X)-24-3, 3))\n",
    "for i in range(len(X)-24-3):\n",
    "    rf_X[i] = X[i:i+24].flatten()\n",
    "    rf_y[i] = y[i+24:i+24+3]\n",
    "    \n",
    "tscv = TimeSeriesSplit(n_splits=6, max_train_size=rf_X.shape[0]//2) # I'll give it more train data than before\n",
    "split = tscv.split(rf_X, rf_y)\n",
    "    \n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [15],\n",
    "    'min_samples_split': [2],\n",
    "    'max_features': [0.5, 1.0],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=randomstate, n_jobs=n_cpu-2),\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    param_grid=param_grid,\n",
    "    cv=split,\n",
    "    verbose=4,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "results = grid_search.fit(rf_X, rf_y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24a7952af770b533"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Best parameters: {results.best_params_}\")\n",
    "print(f\"Best score: {results.best_score_}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d00cc85fc6b47294"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test size tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7019ea007708dee1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "It might also be worth to check smaller test sizes, since we can retrain the model per month for example. I suspect as we move away from the training data, predictions get worse."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "839bfaf45a4abf43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=6, max_train_size=rf_X.shape[0]//3, test_size=24*30*2)  # 2 months of test data\n",
    "split = tscv.split(rf_X, rf_y)\n",
    "\n",
    "score = cross_val_score(\n",
    "    RandomForestRegressor(random_state=randomstate, n_jobs=n_cpu-2, max_depth=15, max_features=0.5, min_samples_split=2, n_estimators=150),\n",
    "    rf_X, rf_y,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=split,\n",
    "    verbose=4,\n",
    ")\n",
    "\n",
    "print(f\"Mean score: {score.mean()}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a71461e2b75ce25d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We get very inconsistent testing results, I'll increase test size to 6 months.\n",
    "I also want to try a higher depth."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "674f8932e6650a9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Depth tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83a986005f917f2b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=6, max_train_size=rf_X.shape[0]//3, test_size=24*30*6)  # 6 months of test data\n",
    "split = tscv.split(rf_X, rf_y)\n",
    "\n",
    "score = cross_val_score(\n",
    "    RandomForestRegressor(random_state=randomstate, n_jobs=n_cpu-2, max_depth=25, max_features=0.5, min_samples_split=2, n_estimators=150),\n",
    "    rf_X, rf_y,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=split,\n",
    "    verbose=4,\n",
    ")\n",
    "\n",
    "print(f\"Mean score: {score.mean()}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b43615ff241360ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "I think depth made a difference, but test size might be working against us.\n",
    "I'll also remove the limit on training size."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ace8e3b7367d1849"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df: pd.DataFrame = df.drop(columns=['covid'], errors='ignore')\n",
    "\n",
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = df['el_load'].to_numpy(dtype=np.float32)\n",
    "rf_X = np.zeros((len(X)-24-3, 24*X.shape[1]))\n",
    "rf_y = np.zeros((len(X)-24-3, 3))\n",
    "for i in range(len(X)-24-3):\n",
    "    rf_X[i] = X[i:i+24].flatten()\n",
    "    rf_y[i] = y[i+24:i+24+3]\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=6)\n",
    "split = tscv.split(rf_X, rf_y)\n",
    "\n",
    "score = cross_val_score(\n",
    "    RandomForestRegressor(random_state=randomstate, n_jobs=n_cpu-2, max_depth=50, max_features=0.75, n_estimators=150),\n",
    "    rf_X, rf_y,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=split,\n",
    "    verbose=4,\n",
    ")\n",
    "\n",
    "print(f\"Mean score: {score.mean()}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db1bc6b75dfbe972"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df: pd.DataFrame = df.drop(columns=['covid'], errors='ignore')\n",
    "\n",
    "X = df.to_numpy(dtype=np.float32)\n",
    "y = df['el_load'].to_numpy(dtype=np.float32)\n",
    "rf_X = np.zeros((len(X)-24-3, 24*X.shape[1]))\n",
    "rf_y = np.zeros((len(X)-24-3, 3))\n",
    "for i in range(len(X)-24-3):\n",
    "    rf_X[i] = X[i:i+24].flatten()\n",
    "    rf_y[i] = y[i+24:i+24+3]\n",
    "    \n",
    "rf = RandomForestRegressor(random_state=randomstate, n_jobs=n_cpu-2, max_depth=50, max_features=0.75, n_estimators=150)\n",
    "splitpoint = rf_X.shape[0] // 7  # to stay consistent with the other models\n",
    "rf.fit(rf_X[:-splitpoint], rf_y[:-splitpoint])\n",
    "\n",
    "TSMWrapper.print_evaluation_info(rf.predict(rf_X[-splitpoint:]), rf_y[-splitpoint:])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9dda389da3ac1e01"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
